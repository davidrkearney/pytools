{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/b7/34eec2fe5a49718944e215fde81288eec1fa04638aa3fb57c1c6cd0f98c3/beautifulsoup4-4.8.0-py3-none-any.whl\n",
      "Collecting soupsieve>=1.2 (from beautifulsoup4)\n",
      "  Using cached https://files.pythonhosted.org/packages/35/e3/25079e8911085ab76a6f2facae0771078260c930216ab0b0c44dc5c9bf31/soupsieve-1.9.2-py2.py3-none-any.whl\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.8.0 soupsieve-1.9.2\n",
      "Collecting requests\n",
      "  Using cached https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests)\n",
      "  Using cached https://files.pythonhosted.org/packages/e6/60/247f23a7121ae632d62811ba7f273d0e58972d75e58a94d329d51550a47d/urllib3-1.25.3-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Using cached https://files.pythonhosted.org/packages/69/1b/b853c7a9d4f6a6d00749e94eb6f3a041e342a885b87340b79c1ef73e3a78/certifi-2019.6.16-py2.py3-none-any.whl\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting idna<2.9,>=2.5 (from requests)\n",
      "  Using cached https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl\n",
      "Installing collected packages: urllib3, certifi, chardet, idna, requests\n",
      "Successfully installed certifi-2019.6.16 chardet-3.0.4 idna-2.8 requests-2.22.0 urllib3-1.25.3\n",
      "Collecting html5lib\n",
      "  Using cached https://files.pythonhosted.org/packages/a5/62/bbd2be0e7943ec8504b517e62bab011b4946e1258842bc159e5dfde15b96/html5lib-1.0.1-py2.py3-none-any.whl\n",
      "Collecting webencodings (from html5lib)\n",
      "  Using cached https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\n",
      "Collecting six>=1.9 (from html5lib)\n",
      "  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Installing collected packages: webencodings, six, html5lib\n",
      "Successfully installed html5lib-1.0.1 six-1.12.0 webencodings-0.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip3 install beautifulsoup4\n",
    "\n",
    "! pip3 install requests\n",
    "\n",
    "! pip3 install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[0m\u001b[01;35mattribute_histogram_plots.png\u001b[0m\r\n",
      " cn-export-all-06-30-2019.csv\r\n",
      " \u001b[01;35mFellowCount.png\u001b[0m\r\n",
      " \u001b[01;35mfig1.png\u001b[0m\r\n",
      " \u001b[01;35mfig2.png\u001b[0m\r\n",
      " \u001b[01;34mNewFaces\u001b[0m/\r\n",
      " new_faces_clean.csv\r\n",
      " NF_Alum_Clean.csv\r\n",
      " \u001b[01;35mnf_areas.png\u001b[0m\r\n",
      " nf_cleaned_dept.csv\r\n",
      " nf_complete.csv\r\n",
      " NF_Replaced.csv\r\n",
      " NF_Reports\r\n",
      " \u001b[01;35mnf_titles.png\u001b[0m\r\n",
      " README.md\r\n",
      "'Step 2 Get, Clean, and Prepare Data.ipynb'\r\n",
      "'Step 3 Discover, Explore, and Visualize Data.ipynb'\r\n",
      "'Step 4 select a model and train it.ipynb'\r\n",
      " Webscraping.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.marquette.edu/polisci/faculty_brooks.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = requests.get(url)\n",
    "coverpage = r1.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1 = BeautifulSoup(coverpage, 'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h2>Director of Undergraduate Studies</h2>,\n",
       " <h2>Faculty &amp; Staff Directory</h2>,\n",
       " <h2>CONTACT</h2>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverpage_news = soup1.find_all('h2')\n",
    "coverpage_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Faculty & Staff Directory'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverpage_news[1].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.bbc.com/sport/football/46897172\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use try-except incase the request was unsuccessful because of \n",
    "# wrong URL\n",
    "try:\n",
    "   page = urlopen(url)\n",
    "except:\n",
    "   print(\"Error opening the URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = soup.find('div', {\"class\": \"story-body sp-story-body gel-      body-copy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'findAll'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f676b463c868>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'findAll'"
     ]
    }
   ],
   "source": [
    "article = ''\n",
    "for i in content.findAll('p'):\n",
    "    article = article + ' ' +  i.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scraped_text.txt', 'w') as file:\n",
    "    file.write(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cristiano Ronaldo's header was enough for Juventus to beat AC Milan and claim a record eighth Supercoppa Italiana in a game played in Jeddah, Saudi Arabia. The Portugal forward nodded in Miralem Pjanic's lofted pass in the second half to settle a meeting between Italian football's two most successful clubs. It was Ronaldo's 16th goal of the season for the Serie A leaders. Patrick Cutrone hit the crossbar for Milan, who had Ivorian midfielder Franck Kessie sent off. Gonzalo Higuain, reportedly the subject of interest from Chelsea, was introduced as a substitute by Milan boss Gennaro Gattuso in Italy's version of the Community Shield. But the 31-year-old Argentina forward, who is currently on loan from Juventus, was unable to deliver an equalising goal for the Rossoneri, who were beaten 4-0 by Juve in the Coppa Italia final in May.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# specify the url\n",
    "url = \"https://www.bbc.com/sport/football/46897172\"\n",
    "\n",
    "# Connect to the website and return the html to the variable ‘page’\n",
    "try:\n",
    "    page = urlopen(url)\n",
    "except:\n",
    "    print(\"Error opening the URL\")\n",
    "\n",
    "# parse the html using beautiful soup and store in variable `soup`\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "# Take out the <div> of name and get its value\n",
    "content = soup.find('div', {\"class\": \"story-body sp-story-body gel-body-copy\"})\n",
    "\n",
    "article = ''\n",
    "for i in content.findAll('p'):\n",
    "    article = article + ' ' +  i.text\n",
    "print(article)\n",
    "\n",
    "# Saving the scraped text\n",
    "with open('scraped_text.txt', 'w') as file:\n",
    "    file.write(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'findAll'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-c88a504de896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'findAll'"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# specify the url\n",
    "url = \"https://www.bbc.com/news/world-asia-49258923\"\n",
    "\n",
    "# Connect to the website and return the html to the variable ‘page’\n",
    "try:\n",
    "    page = urlopen(url)\n",
    "except:\n",
    "    print(\"Error opening the URL\")\n",
    "\n",
    "# parse the html using beautiful soup and store in variable `soup`\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "# Take out the <div> of name and get its value\n",
    "content = soup.find('div', {\"class\": \"story-body sp-story-body gel-body-copy\"})\n",
    "\n",
    "article = ''\n",
    "for i in content.findAll('p'):\n",
    "    article = article + ' ' +  i.text\n",
    "print(article)\n",
    "\n",
    "# Saving the scraped text\n",
    "with open('scraped_text.txt', 'w') as file:\n",
    "    file.write(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
